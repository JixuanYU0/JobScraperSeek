# Seek Job Scraper - HR & Recruitment

Automated scraping tool that collects Human Resources & Recruitment job listings from seek.com.au, **excluding recruitment agencies and their job postings**.

## ğŸ¯ Features

- âœ… Scrapes HR & Recruitment jobs from Seek
- âœ… **Excludes 59 recruitment agencies** (Hays, Michael Page, Robert Walters, etc.)
- âœ… Excludes "Recruitment - Agency" subcategory
- âœ… Extracts detailed job metadata (title, company, location, salary, description, etc.)
- âœ… De-duplicates listings across runs
- âœ… Configurable scheduling (daily or custom intervals)
- âœ… Multiple output formats (JSON, CSV)
- âœ… Comprehensive logging
- âœ… Modular and extensible architecture

## ğŸ“¦ Installation

### Prerequisites

- Python 3.8+
- pip

### Quick Setup

```bash
# Run the setup script
./setup.sh

# Or manually:
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
playwright install chromium
```

## ğŸš€ Usage

### Basic Usage

```bash
# Activate virtual environment
source venv/bin/activate

# Run the scraper
python main.py
```

### Command Line Options

```bash
# Use custom config file
python main.py --config path/to/config.yaml

# Disable deduplication
python main.py --no-dedup

# Save as both JSON and CSV
python main.py --output-format both

# Run in non-headless mode (see browser)
python main.py --headless false
```

## âš™ï¸ Configuration

Edit [config/config.yaml](config/config.yaml) to customize:

```yaml
scraper:
  base_url: "https://www.seek.com.au"
  classification: "Human Resources & Recruitment"

  # Filter by subcategory
  excluded_subcategories:
    - "Recruitment - Agency"

  # Filter by company (59 agencies pre-configured)
  excluded_companies:
    - "Hays"
    - "Michael Page"
    - "Robert Walters"
    # ... and 56 more

  max_pages: 20
  headless: true

storage:
  type: "json"
  output_dir: "data"

logging:
  level: "INFO"
  console: true

deduplication:
  retention_days: 30
```

**See [FILTERING_GUIDE.md](FILTERING_GUIDE.md) for details on managing excluded agencies.**

## ğŸ“… Scheduling

### Using Cron (macOS/Linux)

```bash
# Edit crontab
crontab -e

# Add this line to run daily at 9 AM
0 9 * * * cd /path/to/JobScraperSeek && ./schedule_scraper.sh

# Or hourly
0 * * * * cd /path/to/JobScraperSeek && ./schedule_scraper.sh
```

### Manual Scheduling

```bash
./schedule_scraper.sh
```

## ğŸ“Š Output Schema

### JSON Format
```json
{
  "title": "HR Business Partner",
  "company": "XYZ Pty Ltd",
  "location": "Sydney NSW",
  "salary": "$100,000 - $120,000",
  "classification": "Human Resources & Recruitment",
  "subcategory": "HR - Generalist",
  "posted_date": "2025-10-09",
  "job_url": "https://www.seek.com.au/job/12345678",
  "description": "...",
  "scraped_at": "2025-10-09T09:00:00"
}
```

## ğŸ“ Project Structure

```
JobScraperSeek/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml           # Configuration file
â”œâ”€â”€ data/                     # Output data directory
â”‚   â”œâ”€â”€ jobs_2025-10-09.json
â”‚   â””â”€â”€ seen_jobs.json        # Deduplication tracking
â”œâ”€â”€ logs/                     # Log files
â”‚   â””â”€â”€ scraper_2025-10-09.log
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/               # Data models
â”‚   â”‚   â””â”€â”€ job.py
â”‚   â”œâ”€â”€ scraper/              # Scraping logic
â”‚   â”‚   â””â”€â”€ seek_scraper.py
â”‚   â”œâ”€â”€ storage/              # Storage backends
â”‚   â”‚   â”œâ”€â”€ json_storage.py
â”‚   â”‚   â””â”€â”€ csv_storage.py
â”‚   â””â”€â”€ utils/                # Utilities
â”‚       â”œâ”€â”€ config_loader.py
â”‚       â”œâ”€â”€ logger.py
â”‚       â””â”€â”€ deduplicator.py
â”œâ”€â”€ main.py                   # Main entry point
â”œâ”€â”€ schedule_scraper.sh       # Scheduler script
â”œâ”€â”€ setup.sh                  # Setup script
â””â”€â”€ requirements.txt          # Dependencies
```

## ğŸ” How It Works

1. **Configuration Loading**: Loads settings from [config/config.yaml](config/config.yaml)
2. **Browser Launch**: Uses Playwright to launch a Chromium browser
3. **URL Building**: Creates Seek URL with filters:
   - Classification: `jobs-in-human-resources-recruitment`
   - Date range: `daterange=3` (last 3 days)
   - Subcategories: `subclassification=6323,6322,...` (excludes agency at source)
4. **Navigation**: Direct navigation to filtered URL - no clicking needed!
5. **Scraping**: Extracts job data from search result pages
6. **Three-Layer Filtering**:
   - Layer 1: Subclassification IDs (filters at Seek's server)
   - Layer 2: Subcategory text matching ("Recruitment - Agency")
   - Layer 3: Company name matching (59 recruitment agencies)
7. **Deduplication**: Checks against previously seen jobs
8. **Storage**: Saves to JSON/CSV with timestamp
9. **Logging**: Records all activities to log file

**Efficiency:** Source-level filtering means ~60% fewer pages to scrape! See [SUBCLASSIFICATION_GUIDE.md](SUBCLASSIFICATION_GUIDE.md) for details.

## ğŸ›¡ï¸ Best Practices

### Respectful Scraping

- Default 2-second delay between pages
- Respects Seek's robots.txt
- Uses realistic user agents
- Configurable retry logic

### Rate Limiting

To avoid overwhelming Seek's servers:
- Run once daily (recommended)
- Use headless mode in production
- Monitor logs for errors

## ğŸ”§ Troubleshooting

### Browser Installation Issues

```bash
# Reinstall Playwright browsers
playwright install chromium --force
```

### Permission Denied

```bash
chmod +x setup.sh
chmod +x schedule_scraper.sh
```

### Module Not Found

```bash
# Ensure virtual environment is activated
source venv/bin/activate
pip install -r requirements.txt
```

## ğŸ“ˆ Success Metrics

| Metric | Target |
|--------|--------|
| HR job coverage (no agency) | â‰¥95% accuracy |
| Duplicate rate | <5% |
| Error rate per run | <2% |
| Run frequency | 1x daily minimum |

## ğŸš§ Future Enhancements

- [ ] Airtable integration
- [ ] PostgreSQL/Supabase storage
- [ ] Email/Slack notifications
- [ ] Dashboard for analytics
- [ ] API endpoint for job data
- [ ] Multi-classification support
- [ ] Advanced filtering rules

## ğŸ“ License

This tool is for internal use at LiquidHR. Please ensure compliance with Seek's Terms of Service.

## ğŸ¤ Contributing

For questions or improvements, contact the LiquidHR development team.

---

**Built with â¤ï¸ by LiquidHR**
